# Deep-Learning-Paper-List

## Architecture

  1. [Deep Residual Learning for Image Recognition]() Kaiming. He, Xiangyu. Zhang, Shaoqing. Ren, Jian. Sun. CVPR, 2016.
  2. [Identity Mappings in Deep Residual Networks]() Kaiming. He, Xiangyu. Zhang, Shaoqing. Ren, Jian. Sun. ECCV, 2016.
  3. [Deep Residual Networks: Deep Learning Gets Way Deeper]() Kaiming He. ICML Tutorial, 2016.
  4. [Residual Networks Behave Like Ensembles of Relatively Shallow Networks]() Andreas. Veit, Micheal. Wilber, Serge. Belongie. 2016.

## Loss & Optimization

### Global and Local Minima, Saddle Points
  1. [On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima](https://arxiv.org/abs/1609.04836) N. S. Keskar, D. Mudidere, J. Nocedal, M. Smelyanskiy, P. T. P. Tang.
  2. [The Loss Surfaces of Multilayer Networks](https://arxiv.org/abs/1412.0233) A. Choromanska, M. Henaff, M. Mathieu, G. B. Arous, Y. LeCun.
  3. [Escaping from Saddle Points](https://arxiv.org/abs/1503.02101) - Online Stochastic Gradients for Tensor Decomposition. Rong Ge, Furong Huang, Chi Jin, Yang Yuan.
  4. [Deep Learning without Poor Local Minima](https://arxiv.org/abs/1605.07110) K. Kawaguchi.


### Optimization Algorithm

  1. [rmsprop: Divide the gradient by a running average of its recent magnitude](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf) G. Hinton, Nitish Srivastava, Kevin Swersky.
  2. [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf). J. Duchi, E. Hazan, Y. Singer. JMLR, 2011.
  3. [Adadelta - an adaptive learning rate method](http://arxiv.org/abs/1212.5701) Matthew D. Zeiler
  4. [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8) Diederik P. Kingma, Jimmy Ba.
  5. [Incorporating Nesterov Momentum into Adam](http://cs229.stanford.edu/proj2015/054_report.pdf) Timothy Dozat.
  
  
# Applications

## Embeddings

  1. [Distributed Representations of Words and Phrases and their Compositionality]() T. Mikolov, I. Sutskever, Kai Chen, G. Corrado, J. Dean
  2. [Representations in Vector Space Efficient Estimation of Word Representations in Vector Space]() T. Mikolov, Kai Chen, G. Corrado, J. Dean
  3. [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf) Jeffrey Pennington, Richard Socher, Christopher D. Manning

## Image Classification

  - [ImageNet Classification with Deep Convolutional
     Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton. NIPS.
  - [Deep Residual Learning for Image Recognition]() Kaiming. He, Xiangyu. Zhang, Shaoqing. Ren, Jian. Sun. CVPR, 2016.
  - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852) Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun

## Text Classification

  - [Convolutional Neural Networks for Sentence Classificatio]() Yoon Kim.
  - [Bag of Tricks for Efficient Text Classification]() A. Joulin, E. Grave, P. Bojanowski, T. Mikolov. 
  - [Text understanding from scratch]()  Xiang Zhang and Yann LeCun. 2015.
  - [Character-level convolutional networks for text classification]()  Xiang Zhang, Junbo Zhao, and Yann LeCun. NIPS, 2015.

## Machine Translation

  1. [Statistical Phrase-based Translation]() P. Koehn, F. J. Och, D. Marcu. NAACL, 2003.
  2. [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches]() K. Cho, B. v. Merrienboer, D. Bahdanau, Y. Bengio
  3. [Recurrent Continuous Translation Models]() N. Kalchbrenner, P. Blunsom. 2013.
  4. [Sequence to Sequence Learning with Neural Networks]() I. Sutskever, O. Vinyals, Q. V. Le. 2014.
  5. [Neural Machine Translation by Jointly Learning to Align and Translate]() D. Bahdanau, K. Cho, Y. Bengio, 2014.
  6. [On using very large target vocabulary for neural machine translation]() S. Jean, K. Cho, R. Memisevic, Y. Bengio. ACL, 2015.
  7. [Addressing the Rare Word Problem in Neural Machine Translation]() Minh-Thang Luong, I. Sutskever, Q. V. Le, O. Vinyals, W. Zaremba.
  8. [Neural Machine Translation of Rare Words with Subword Units]() R. Sennrich, B. Haddow, A. Birch.
  9. [Deep Residual Learning for Image Recognition]() Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. CVPR, 2015.

## Question Answering

  1. [Memory Networks. J. Weston, S. Chopra, A. Bordes]() arXiv, 2015.
  2. [End-to-End Memory Networks]() S. SukhbaatarM A. Szlam, J. Weston, R. Fergus. arXiv, 2015.
  3. [Iterative Alternating Neural Attention for Machine Reading]() A. Sordoni, P. Bachman, Y. Bengio. arXiv, 2016.
  4. [Key-Value Memory Networks for Directly Reading Documents]() A. Miller, A. Fisch, J. Dodge, A. Karimi, A. Bordes, J. Weston. arXiv, 2016.
  5. [Question Answering with Subgraph Embedding]() A. Bordes, J. Weston, S. Chopra. arXiv, 2014

## Knowledge Graph